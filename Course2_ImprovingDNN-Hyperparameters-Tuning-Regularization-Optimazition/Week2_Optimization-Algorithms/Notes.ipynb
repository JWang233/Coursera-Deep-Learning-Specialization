{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Batch GD:**\n",
    "    - Same as we learned before: process all the training set/ all the batch at the same time.\n",
    "\n",
    "\n",
    "- **Mini-batch GD:**\n",
    "    - Process some smaller training sets at the same time, also known as mini-batches\n",
    "    - New notation: $X^{\\{t\\}} :(n_{x}, t), \\; Y^{\\{t\\}} : (1, t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:**\n",
    "\n",
    "for t = 1, ..., 5000 {\n",
    "    \n",
    "1. Forward propogation on $X^{\\{t\\}}$\n",
    "    - vectorized implementation\n",
    "2. Compute cost: $J^{\\{t\\}}$, which is based on the mini-batch $X^{\\{t\\}}, Y^{\\{t\\}}$\n",
    "3. Backward propogation to compute gradients using the cost  \n",
    "4. Update parameters $W^{[l]}, b^{[l]}$\n",
    "\n",
    "} \n",
    "\n",
    "Running all the iterations here is called \"**1 epoch**\" (1 pass through all the training set/mini-batches) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Mini-batch GD:**\n",
    "\n",
    "- **Difference:**\n",
    "\n",
    "    ![](./imgs/mini-vs-all.jpg)\n",
    "    \n",
    "    - The reason is that some mini-batches may work well in current neural networks, while others may not, i.e. some fake training examples.\n",
    "    \n",
    "\n",
    "- **Mini-batch Size:**\n",
    "    - Mini-batch size = m: Batch GD (the entire training set is one batch)\n",
    "        - Time-consuming. \n",
    "    - Mini-batch size = 1: Stochastic GD (every example is its own mini-batch)\n",
    "        - It won't converge. Eventually it will stay around the global minimum.\n",
    "        - Lose speedup from vectorization. \n",
    "    - In practice: between 1 to m. Not too big/small. \n",
    "        - Fastest lerning: 1) vectorization ~ 1,000, 2) make progresss without passsing entire training set. \n",
    "    \n",
    "    ![](./imgs/batch-size.jpg)\n",
    "\n",
    "    - **How to chose:**\n",
    "        - if small train set ($m \\leq 2000$) : use **batch GD**\n",
    "        - typical mini-batch size: 64, 128, 256, 512, (some number equal to **the power of 2** )\n",
    "            - Make sure mini-batch fit in CPU/GPU memory; otherwise, it becomes worse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exponentially Weighted Averages (EWA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forlumar:**\n",
    "\n",
    "$$ V_{t} = \\beta \\; V_{t-1} + (1 - \\beta) \\; \\theta_{t} $$\n",
    "\n",
    "- $\\beta$ can be considered as the average of several $\\frac{1}{1-\\beta}$ days. \n",
    "    - $\\beta = 0.9$ : ~ 10 days average (red line)\n",
    "        - did show adaptive\n",
    "    - $\\beta = 0.98$ : ~ 50 days average (green line)\n",
    "        - go smooth because of the larger window size, so it adapts slower and showd a right shift \n",
    "    - $\\beta = 0.5$ : ~ 2 days average (yellow line) \n",
    "        - adaptive faster\n",
    "\n",
    "    ![](./imgs/ewa-ie.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Exponentially Weighted Averages:**\n",
    "\n",
    "- Expand the formular: \n",
    "\n",
    "    $$ V_{t} = \\sum_{i=1}^{t} \\; (1 - \\beta) \\; \\beta^{(t - i)} \\; V_{i} $$\n",
    "\n",
    "    - where $(1 - \\epsilon)^{\\frac{1}{\\epsilon}} \\approx \\frac{1}{e} $, which means the exponential curve will approximate 0 after greater than $\\epsilon$. Thus, it feels like only $\\epsilon$ days are been averaged while the other days have very small weights. \n",
    "        - Let $\\epsilon = 1 - \\beta$ , now we can understand the example above.\n",
    "\n",
    "\n",
    "- In practice: \n",
    "\n",
    "    ![](./imgs/ewa-formular.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias Correction in EWA:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purple line below shows the bias in EWA which is caused by the initialization step $V_{0} = 0$ .  \n",
    "\n",
    "![](./imgs/ewa-bias.jpg)\n",
    "\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "- Instead of taking $V_{t}$ for the next iteration, taking $\\frac{V^{t}}{1 - \\beta^{t}} $. \n",
    "    - Note that as $t$ goes larger, $1 - \\beta^{t} \\rightarrow 0 $. Thus, it will finally overlay with the original formular. \n",
    "\n",
    "    ![](./imgs/ewa-bias-fix.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Algorithms with Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "\n",
    "- Let the gradient descent converge faster. In the counter map, it moves slowly in the vertical direction but faster in the horizaontal direction. \n",
    "\n",
    "    ![](./imgs/gdm.jpg)\n",
    "\n",
    "- How to do it? Introduce momentum into Gradient Descent. Like the example above, use Exponentially Weighted Average to smooth the gradients so that we can use a larger learnign rate and rapidly reach the global minimum. \n",
    "\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "- Only need to add two lines before updating the parameters \n",
    "\n",
    "    On iteration t: \n",
    "    \n",
    "    Compute gradients on current mini-batch\n",
    "    \n",
    "$$ v_{dw} = \\beta \\; v_{dw} + (1 - \\beta) \\; dw $$\n",
    "$$ v_{db} = \\beta \\; v_{db} + (1 - \\beta) \\; db $$\n",
    "\n",
    "$$ W = W - \\alpha \\; v_{dw} $$\n",
    "$$ b = b - \\alpha \\; v_{db} $$\n",
    "\n",
    "- Hyperparameters: $\\beta$\n",
    "\n",
    "**In practice:**\n",
    "- Just simply initialize $v_{dw}, v_{db}$ as 0, because only about 10 iterations it will be same.\n",
    "- Removing $(1-\\beta)$ . However, it becomes less intuitive, and just a scaling problem for the previous gradients. Some people use it while others not. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Root Mean Square Propogation (RMSprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:**\n",
    "\n",
    "- Try to control the gradient descent between parameters so that it can reduce vertical oscillations while move faster in the horizontal way. \n",
    "\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "Initialize: \n",
    "$$ S_{dw} = 0, \\; S_{db} = 0 $$\n",
    "\n",
    "One iteration t: \n",
    "\n",
    "Compute gradients on current mini-batch\n",
    "\n",
    "$$ S_{dw} = \\beta_{2} \\; S_{dw} + (1 - \\beta_{2}) \\; dW^{2} $$\n",
    "$$ S_{db} = \\beta_{2} \\; S_{db} + (1 - \\beta_{2}) \\; db^{2} $$\n",
    "\n",
    "$$ W := W - \\alpha \\; \\frac{dW}{\\sqrt{S_{dw}}} $$\n",
    "$$ b := b - \\alpha \\; \\frac{db}{\\sqrt{S_{db}}} $$\n",
    "\n",
    "**Note:**\n",
    "- Once one parameter is too large, by dividing its rooted gradients can make it smaller. Vice versa.\n",
    "- The rooted gradients should not be zero, so add a tiny $\\epsilon \\approx 10^{-8}$ to the demoninator when programming.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Adam Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:**\n",
    "\n",
    "- The combination of Momentum and RMSprop. The most commonly used optimization algorithm. \n",
    "- It's called Adaptive Moment Estimation: the first moment is $\\beta_{1}$ while the second moment is $\\beta_{2}$. \n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "- Initialize: \n",
    "\n",
    "$$ V_{dw} = 0, \\; V_{db} = 0, \\; S_{dw} = 0, \\; S_{db} = 0 $$\n",
    "\n",
    "- On iteratin t: \n",
    "\n",
    "    - compute $dw, db$ on current min-batch\n",
    "    \n",
    "    $$ V_{dw} = \\beta_{1} \\; V_{dw} + (1 - \\beta_{1}) \\; dw \\tag{1}$$\n",
    "    $$ V_{db} = \\beta_{1} \\; V_{db} + (1 - \\beta_{1}) \\; db \\tag{2}$$\n",
    "    \n",
    "    $$ S_{dw} = \\beta_{2} \\; S_{dw} + (1 - \\beta_{2}) \\; dw^2 \\tag{3}$$\n",
    "    $$ S_{db} = \\beta_{2} \\; S_{db} + (1 - \\beta_{2}) \\; db^2 \\tag{4}$$\n",
    "    \n",
    "    $$ V_{dw}^{corrected} = V_{dw} \\; / \\; (1 - \\beta^{t}_{1}) \\tag{5} $$\n",
    "    $$ V_{db}^{corrected} = V_{db} \\; / \\; (1 - \\beta^{t}_{1}) \\tag{6} $$\n",
    "    \n",
    "    $$ S_{dw}^{corrected} = S_{dw} \\; / \\; (1 - \\beta^{t}_{2}) \\tag{7} $$\n",
    "    $$ S_{db}^{corrected} = s_{db} \\; / \\; (1 - \\beta^{t}_{2}) \\tag{8} $$\n",
    "    \n",
    "    $$ W := W - \\alpha \\; \\frac{V_{dw}^{corrected}}{\\sqrt{S_{dw}^{corrected}} + \\epsilon} \\tag{9}$$\n",
    "    $$ b := b - \\alpha \\; \\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}} + \\epsilon} \\tag{10}$$\n",
    "    \n",
    "- Hyperparameters needed to tune: \n",
    "    \n",
    "    $$\\alpha, \\; \\beta_{1} = 0.9 \\; (\\text{default}), \\; \\beta_{2} = 0.999 \\; (\\text{default}), \\; \\epsilon $$ \n",
    "\n",
    "\n",
    "**Note:**\n",
    "- The equation 1 and 2 are based on Momentum while the equation 3 and 4 are from RMSprop. \n",
    "- All of them should be corrected to remove bias.\n",
    "- A tiny number $\\epsilon$ is added to prevent from being divided by zero, which is fewly tuned. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Learning Rate Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue:**\n",
    "\n",
    "- Fixing the learning rate may not converge if $\\alpha$ is too large. \n",
    "    \n",
    "![](./imgs/fix-learning-rate.jpg)\n",
    "\n",
    "\n",
    "**Solution:**\n",
    "- Gradually reduce the learning rate, also called learning rate decay. \n",
    "\n",
    "$$ \\alpha = \\frac{1}{1 + decay-rate \\; * \\; epoch-num} \\; \\alpha_{0} $$\n",
    "\n",
    "- Hyperparameters: $decay-rate, \\; \\alpha_{0} $\n",
    "\n",
    "**Other Leraning Rate Decay Methods:**\n",
    "\n",
    "![](./imgs/learning-rate-methods.jpg) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Problem of Local Optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/local-optima.jpg)\n",
    "\n",
    "- The left figure is the ideal one, which rarely happen.\n",
    "    - The local optima is the global minimal. \n",
    "- The right figure happens a lot in deep learning, espetially when there are millions of parameters. \n",
    "    - Thus, the local optima is not the global minimal but **the saddle point**. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local optimal are not a problem. The problem is plateaus.**\n",
    "\n",
    "![](./imgs/plateaus.jpg)\n",
    "\n",
    "- because the gradients on the plateaus are very closed to 0, so it makes learning very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Exponentially Weighted Averages, $\\beta$ is very important. Based on the term $\\frac{1}{1-\\beta}$, \n",
    "\n",
    "- The larger the $\\beta$, more days are averaged, so the average goes smooth but less adaptive. \n",
    "- The smaller the $\\beta$, fewer days are averaged, so the average is more oscillated and adaptive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mini-Batch Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two steps:\n",
    "- **Shuffle**: Create a shuffled version of the training set (X, Y) as shown below. Each column of X and Y represents a training example. Note that the random shuffling is done synchronously between X and Y. Such that after the shuffling the $i^{th}$ column of X is the example corresponding to the $i^{th}$ label in Y. The shuffling step ensures that examples will be split randomly into different mini-batches. \n",
    "\n",
    "    ```python\n",
    "    # Codes: \n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "    ```\n",
    "    \n",
    "    ![](./imgs/hw-kiank_shuffle.png)\n",
    "\n",
    "- **Partition**: Partition the shuffled (X, Y) into mini-batches of size `mini_batch_size` (here 64). Note that the number of training examples is not always divisible by `mini_batch_size`. The last mini batch might be smaller, but you don't need to worry about this. When the final mini-batch is smaller than the full `mini_batch_size`, it will look like this: \n",
    "\n",
    "    ![](./imgs/hw-kiank_partition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What you should remember**:\n",
    "- Shuffling and Partitioning are the two steps required to build mini-batches\n",
    "- Powers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the velocity:**\n",
    "\n",
    "The velocity, $v$, is a python dictionary that needs to be initialized with arrays of zeros. Its keys are the same as those in the `grads` dictionary, that is:\n",
    "for $l =1,...,L$:\n",
    "```python\n",
    "v[\"dW\" + str(l+1)] = ... #(zeros with the same shape as parameters[\"W\" + str(l+1)])\n",
    "v[\"db\" + str(l+1)] = ... #(zeros with the same shape as parameters[\"b\" + str(l+1)])\n",
    "```\n",
    "**Note** that the iterator l starts at 0 in the for loop while the first parameters are v[\"dW1\"] and v[\"db1\"] (that's a \"one\" on the superscript). This is why we are shifting l to l+1 in the `for` loop.\n",
    "\n",
    "**Forlumar:**\n",
    "\n",
    "$$ \\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n",
    "\\end{cases}\\tag{1}$$\n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\n",
    "b^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n",
    "\\end{cases}\\tag{2}$$\n",
    "\n",
    "\n",
    "**Note** that:\n",
    "- The velocity is initialized with zeros. So the algorithm will take a few iterations to \"build up\" velocity and start to take bigger steps.\n",
    "- If $\\beta = 0$, then this just becomes standard gradient descent without momentum. \n",
    "\n",
    "**How do you choose $\\beta$?**\n",
    "\n",
    "- The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. \n",
    "- Common values for $\\beta$ range from 0.8 to 0.999. If you don't feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. \n",
    "- Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "- Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.\n",
    "- You have to tune a momentum hyperparameter $\\beta$ and a learning rate $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does Adam work?**\n",
    "1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). \n",
    "2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). \n",
    "3. It updates parameters in a direction based on combining information from \"1\" and \"2\".\n",
    "\n",
    "The update rule is, for $l = 1, ..., L$: \n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta_1 v_{dW^{[l]}} + (1 - \\beta_1) \\frac{\\partial \\mathcal{J} }{ \\partial W^{[l]} } \\\\\n",
    "v^{corrected}_{dW^{[l]}} = \\frac{v_{dW^{[l]}}}{1 - (\\beta_1)^t} \\\\\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "s^{corrected}_{dW^{[l]}} = \\frac{s_{dW^{[l]}}}{1 - (\\beta_2)^t} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{v^{corrected}_{dW^{[l]}}}{\\sqrt{s^{corrected}_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "where:\n",
    "- t counts the number of steps taken of Adam \n",
    "- L is the number of layers\n",
    "- $\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. \n",
    "- $\\alpha$ is the learning rate\n",
    "- $\\varepsilon$ is a very small number to avoid dividing by zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Three Optimization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grandient Descent:**\n",
    "\n",
    "![](./imgs/hw2-gd.png)\n",
    "\n",
    "![](./imgs/hw2-gd-res.png)\n",
    "\n",
    "\n",
    "**Grandient Descent w/ Momentum:**\n",
    "\n",
    "![](./imgs/hw2-gdm.png)\n",
    "\n",
    "![](./imgs/hw2-gdm-res.png)\n",
    "\n",
    "\n",
    "**Adam:**\n",
    "\n",
    "![](./imgs/hw2-adam.png)\n",
    "\n",
    "![](./imgs/hw2-adam-res.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:**\n",
    "\n",
    "![](./imgs/hw2-res.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
