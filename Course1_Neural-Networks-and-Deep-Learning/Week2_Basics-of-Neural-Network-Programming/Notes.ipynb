{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 1. Logistic Regression as a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notations:**\n",
    "\n",
    "- Dataset:  $(x,y), x\\in \\mathbb{R}^{n_{x}}, y \\in \\{0, 1\\}$, where $n_{x}$ is the number of pixels in all bands\n",
    "\n",
    "- Training and Testing data: $ m_{train/test} = \\{(x^{1}, y^{1}), ..., (x^{m}, y^{m}) \\} $\n",
    "\n",
    "- Input data for neural network: \n",
    "    - $$X = [x^{1}, x^{2}, ..., x^{m}] $$\n",
    "    where $X \\in \\mathbb{R}^{n_{x} \\times m}$\n",
    "    \n",
    "    - $$Y = [y^{1}, y^{2}, ..., y^{m}] $$\n",
    "    where $X \\in \\mathbb{R}^{1 \\times m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Concept:**\n",
    "\n",
    "\n",
    "- Given $X$ wants $\\hat{y} = P(y=1 | x)$\n",
    "\n",
    "    where $X \\in \\mathbb{R}^{n_{x}}$, $0 \\leq \\hat{y} \\leq 1$\n",
    "- Parameters: $\\underline{\\omega} \\in \\mathbb{R}^{n_{x}}$, $b \\in \\mathbb{R}$\n",
    "\n",
    "\n",
    "- Outputs: \n",
    "\n",
    "    $ \\hat{y} = \\sigma \\: ( \\omega ^{T}x + b) $\n",
    "\n",
    "    where $ \\sigma(z) = \\frac{1}{1 + e^{-z}} $\n",
    "    \n",
    "    <img src = 'imgs\\sigmoid.png'>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Logistic Regression Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss (Error) Function:**\n",
    "\n",
    "$$\\mathcal{L} (\\hat{y}, y) = -( y \\;\\log \\hat{y} + ( 1 - y) \\; \\log( 1 - \\hat{y}) ) $$\n",
    "\n",
    "Why this? \n",
    "- If $ y = 1: \\: p(y|x) = \\hat{y}$. The chance y given x is equal to 1.\n",
    "- If $ y = 0: \\: p(y|x) = 1 - \\hat{y} $. The chance y given x is equal to 0.\n",
    "- Thus, the probability can be expressed as $$ p(y|x) = \\hat{y}^{y} \\; (1 - \\hat{y})^{1 - y} $$\n",
    "\n",
    "- Since the $ \\log()$ function is **strictly monotonically increasing, maximizing $p(y|x)$ is equal to maximize $\\log(p(y|x) $. Thus, $$ \\log(p(y|x) = y \\log \\hat{y} + ( 1 - y)  \\log( 1 - \\hat{y}) = - \\mathcal{L}(\\hat{y}, y) $$\n",
    "    \n",
    "    where, maximizing the probability is the same as minimizing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost Function:**\n",
    "\n",
    "$$J(w,b) = \\frac{1}{m} \\; \\sum _{i=1}^{m} \\mathcal{L} (\\hat{y} \\; ^{(i)}, y^{(i)}) = - \\frac{1}{m} \\; \\sum _{i=1}^{m}[ y^{(i)} \\log \\hat{y} \\; ^{(i)} + ( 1 - y^{(i)} )  log( 1 - \\hat{y} \\; ^{(i)})) ]  $$\n",
    "\n",
    "Why this? \n",
    "- Assume data is i.i.d\n",
    "- Maximizing $$ \\log P(labels \\; in \\; training \\; set) = \\log \\prod_{i = 1}^{m} p(y^{(i)}, x^{(i)}) $$ $$ \\log P(...) = \\sum_{i=1}^{m} p(y^{(i)}, x^{(i)}) = -\\sum_{i=1}^{m} \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)}) $$ \n",
    "\n",
    "- Using the principle, Maximum Likelihood Estimation, to maximize the probability, so the cost function is minimized. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between Loss & Cost Function:**\n",
    "- The loss function computes the error for a single training example\n",
    "- The cost function is the average of the loss functions of the entire training set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn\\Train the Parameters**\n",
    "\n",
    "- Goal: want to find $w,b$ that minimize $J(w,b)$, which is defined as a convex function for simplfying the optimization\n",
    "\n",
    "<img src = 'imgs\\gd-ill.jpg'>\n",
    "\n",
    "- Algorithm:\n",
    "\n",
    "    Repeat:\n",
    "$$w \\: := \\: w - \\alpha \\; \\frac{\\partial J(w,b)}{\\partial w} $$\n",
    "$$b \\: := \\: b - \\alpha \\; \\frac{\\partial J(w,b)}{\\partial b} $$\n",
    "    \n",
    "    where $\\alpha$ is the learning rate controlling how big a step we take on each iteration, $\\frac{\\partial J(w)}{\\partial w}$, $dw$ used in the following section, is the partial derivative on $w$ representing the basic update or the change we want to make to the parameter $w$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computational Graph:**\n",
    "\n",
    "- forward propogation/pass: \n",
    "\n",
    "    <img src = 'imgs\\computational-graph.jpg'>\n",
    "    \n",
    "- Final Output Variable: $J$\n",
    "    - Notation: $$dvar := \\frac{d \\;FinalOutputVar}{d \\; var}$$\n",
    "    \n",
    "    the derivative of a final output variable with respect to various intermediate quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Derivatives with a Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chain Rule:**\n",
    "\n",
    "- Using the same graph in the above image\n",
    "\n",
    "- Backward calculation: \n",
    "    - Follow the direction from the right to the left to compute the derivatives\n",
    "\n",
    "$$ \\frac{dJ}{dv} = 3; \\:\\:\\:\\:\\: \\frac{dJ}{da} = \\frac{dJ}{dv} \\frac{dv}{da} = 3 \\times 1 = 3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Logistic Regression Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem recap:**\n",
    "<img src = 'imgs\\logis-gd-problem.jpg'>\n",
    "   \n",
    "**Goal:**\n",
    "\n",
    "- Adjust $w_{1}, w_{2}, b$ to minimize the loss function $J$\n",
    "    \n",
    "    <img src = 'imgs\\logis-gd-goal.jpg'>\n",
    "    \n",
    "**Backward derivatives:**\n",
    "\n",
    "- Derivative of the logistic loss function: \n",
    "\n",
    "$$ da = \\frac{d \\; \\mathcal{L}(a,y)}{da} = -\\frac{y}{a} + \\frac{1-y}{1-a} $$\n",
    "\n",
    "- Derivative of the Sigmoid function: \n",
    "\n",
    "$$ \\frac{d}{dx} S(x) = \\frac{d}{dx} \\; \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "$$ = \\frac{e^{-x}}{(1 + e^{-x})^{2}} $$ \n",
    "\n",
    "$$ = \\frac{-1 + 1 + e^{-x}}{(1+ e^{-x})^{2}} $$ \n",
    "\n",
    "$$ = \\frac{1}{1+ e^{-x}} - \\frac{1}{(1+ e^{-x})^{2}} $$ \n",
    "\n",
    "$$ = \\frac{1}{1+ e^{-x}}(1 - \\frac{1}{1+ e^{-x}}) $$ \n",
    "\n",
    "$$ = S(x)\\;(1 - S(x)) $$\n",
    "\n",
    "\n",
    "- \n",
    "    - The reason why the derative is expressed in ths way is that we can use what we already calculated in the forward computation into the backward computation for saving more time.\n",
    "    \n",
    "- Thus, $$ dz = da \\; \\frac{da}{dz} = (-\\frac{y}{a} + \\frac{1-y}{1-a}) \\; a \\; (1-a) = a - y $$ \n",
    "\n",
    "$$ dw_{1} = x_{1} \\: dz$$ $$ dw_{2} = x_{2} \\: dz$$ $$ db = dz$$ \n",
    "\n",
    "- Algorithm: repeat $$ w_{1} := w_{1} - \\alpha \\: dw_{1} $$ $$ w_{2} := w_{2} - \\alpha \\: dw_{2} $$ $$ b := b - \\alpha \\: db $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Gradient Descent on m Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Algorithms:**\n",
    "\n",
    "- Initilization: $ J = 0, dw_{1} = 0, dw_{2} = 0, db = 0$ \n",
    "\n",
    "- For i = 1 to m \n",
    "    $$ z^{i} = w^{T}x^{i} + b $$ \n",
    "    $$ a^{(i)} = \\sigma \\; (z^{i}) $$\n",
    "    \n",
    "    $$ J += -(y^{i}\\log a^{i} + (1 - y^{i})\\log (1 - a^{i}))  $$\n",
    "    $$ dz^{i} = a^{i} - y^{i} $$\n",
    "    $$ dw_{1} \\: += x^{i}_{1} \\: dz^{i} $$\n",
    "    $$ dw_{2} \\: += x^{i}_{2} \\: dz^{i} $$\n",
    "    $$ db \\: +=  dz^{i} $$\n",
    "    \n",
    "- Mean: $ J \\; /= m, \\: dw_{1} \\; /= m, \\: dw_{2} \\; /= m, \\: db \\; /= m $\n",
    "    \n",
    "- Updates: $$ w_{1} := w_{1} - \\alpha \\: dw_{1} $$ $$ w_{2} := w_{2} - \\alpha \\: dw_{2} $$ $$ b := b - \\alpha \\: db $$\n",
    "\n",
    "- Drawbacks: for loop is gonna slow down the entire process, especitally when there are a large number of parameters. Thus, the best solution is vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized Algorithms:**\n",
    "\n",
    "- Forward: \n",
    "\n",
    "$$ Z = w^{[T]} + b $$ \n",
    "\n",
    "$$ A = \\sigma (Z) $$ \n",
    "\n",
    "- Backword: \n",
    "\n",
    "$$ dZ = A - Y $$ \n",
    "\n",
    "$$ dw = \\frac{1}{m} \\; X \\;dZ^{T} $$ \n",
    "\n",
    "$$ db = \\frac{1}{m} \\; \\text{np.sum($dZ$)} $$\n",
    "\n",
    "$$ w := w - \\alpha \\; dw $$ \n",
    "\n",
    "$$ b := b - \\alpha \\; db $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Python and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Vectorization\n",
    "\n",
    "- Vectorization is much faster than the for loop! See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249834.3002996213\n",
      "Vectorized version:0.0ms\n",
      "249834.30029962066\n",
      "For loop:355.0863265991211ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time \n",
    "\n",
    "nNum = 1000000\n",
    "a = np.random.rand(nNum)\n",
    "b = np.random.rand(nNum)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a, b) \n",
    "toc = time.time()\n",
    "print(c)\n",
    "print(\"Vectorized version:\" + str(1000*(toc-tic)) + \"ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time() \n",
    "for i in range(nNum): \n",
    "    c += a[i] * b[i]\n",
    "toc = time.time()\n",
    "print(c)\n",
    "print(\"For loop:\" + str(1000*(toc-tic)) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Neural Network Programming Guideline:\n",
    "\n",
    "- Whenever possible, avoid explicit for-loops! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Broadcasting in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Principle:**\n",
    "\n",
    "- A matrix (m,n)  +-x/ another matrix (1,n) or (m,1), the second matrix will be copied to become the matrix with the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python operation, aix = 0 means the operation in vertical line (column), while axis = 1 means the operation in horizontal line (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 A Not on Python Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71984454]\n",
      " [ 0.29621368]\n",
      " [-0.25412647]\n",
      " [-1.26199709]\n",
      " [-0.03885003]]\n",
      "(5, 1)\n",
      "This is a 5-by-1 vector. ALWAYS use this structure!\n",
      "\n",
      "[ 0.21971449  1.45976932  1.75588662  0.84489119 -0.83085174]\n",
      "(5,)\n",
      "This is a rank 1 array. NEVER use this structure!\n",
      "\n",
      "(5, 1)\n",
      "The rank 1 array has been reshaped to a vector!\n"
     ]
    }
   ],
   "source": [
    "# vector\n",
    "a = np.random.randn(5, 1)\n",
    "print(a)\n",
    "print(np.shape(a))\n",
    "print(\"This is a 5-by-1 vector. ALWAYS use this structure!\\n\")\n",
    "\n",
    "# rank 1 array\n",
    "a = np.random.randn(5)\n",
    "print(a)\n",
    "print(np.shape(a))\n",
    "print(\"This is a rank 1 array. NEVER use this structure!\\n\")\n",
    "\n",
    "# fix rank 1 array \n",
    "a = a.reshape(5,1)\n",
    "print(np.shape(a))\n",
    "print(\"The rank 1 array has been reshaped to a vector!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix and Element-wise Multiplication:** \n",
    "- np.dot(a,b) performs a matrix multiplication on a and b\n",
    "\n",
    "- a*b performs an element-wise multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Normalizing Rows:**\n",
    "\n",
    "- After **normalization**, gradient descent converges faster so it often leads to a better performance!\n",
    "\n",
    "- Method: dividing each row vector of x by its norm (square root of the sum of squares). Sometimes, normalizing imagse is by subtracting dataset's image mean instead of each image mean in DL. \n",
    "\n",
    "    - The reason we do both of those things is because in the process of training our network, we're going to be multiplying (weights) and adding to (biases) these initial inputs in order to cause activations that we then backpropogate with the gradients to train the model.\n",
    "    \n",
    "    We'd like in this process for each feature to have a similar range so that our gradients don't go out of control (and that we only need one global learning rate multiplier).\n",
    "\n",
    "    Another way you can think about it is deep learning networks traditionally share many parameters - if you didn't scale your inputs in a way that resulted in similarly-ranged feature values (ie: over the whole dataset by subtracting mean) sharing wouldn't happen very easily because to one part of the image weight w is a lot and to another it's too small. \n",
    "    \n",
    "    (From [stackoverflow](https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current))\n",
    "\n",
    "- One example, if $$x = \n",
    "\\begin{bmatrix}\n",
    "    0 & 3 & 4 \\\\\n",
    "    2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}$$ then $$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix} $$and        $$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}$$ Note that you can divide matrices of different sizes and it works fine: this is called broadcasting and you're going to learn about it in part 5.\n",
    "\n",
    "\n",
    "- Image Dataset is more convenient and works almost as well to jsut scale the data to [0, 1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Softmax Function:**\n",
    "\n",
    "- $ \\text{for } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} $ \n",
    "\n",
    "- $\\text{for a matrix } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }$  $$softmax(x) = softmax\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \\begin{pmatrix}\n",
    "    softmax\\text{(first row of x)}  \\\\\n",
    "    softmax\\text{(second row of x)} \\\\\n",
    "    ...  \\\\\n",
    "    softmax\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. A trick in np.reshape()**\n",
    "\n",
    "- -1 is used to let the numpy to figure the dimension of the matrix/vector by itself. \n",
    "\n",
    "- A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T \n",
    "```\n",
    "    \n",
    "- More details can be found in [stackoverflow](https://stackoverflow.com/questions/18691084/what-does-1-mean-in-numpy-reshape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Learning Rate Tuning:**\n",
    "\n",
    "- Different learning rates $\\alpha$ give different costs and thus different predictions results. The learning rate determines how rapidly we update the parameters. If the learning rate is too large we may \"overshoot\" the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That's why it is crucial to use a well-tuned learning rate.\n",
    "\n",
    "<img src = 'imgs\\learning-rate-tuning.png'>\n",
    "\n",
    "- If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost). \n",
    "\n",
    "- A lower cost doesn't mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.\n",
    "\n",
    "- In deep learning, we usually recommend that you: \n",
    "    \n",
    "    - Choose the learning rate that better minimizes the cost function.\n",
    "    \n",
    "    - If your model overfits, use other techniques to reduce overfitting. (We'll talk about this in later videos.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression with a Neural Network mindset v5**\n",
    "\n",
    "- Framework: \n",
    "\n",
    "    <img src = 'imgs\\proj-cat.png'>\n",
    "    \n",
    "- Mathematical expression of the algorithm: \n",
    "\n",
    "    For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "    The cost is then computed by summing over all training examples:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "\n",
    "- Final Outputs: \n",
    "    \n",
    "    - Cost: \n",
    "    ```Python\n",
    "    Cost after iteration 0: 0.693147\n",
    "    Cost after iteration 100: 0.584508\n",
    "    Cost after iteration 200: 0.466949\n",
    "    Cost after iteration 300: 0.376007\n",
    "    Cost after iteration 400: 0.331463\n",
    "    Cost after iteration 500: 0.303273\n",
    "    Cost after iteration 600: 0.279880\n",
    "    Cost after iteration 700: 0.260042\n",
    "    Cost after iteration 800: 0.242941\n",
    "    Cost after iteration 900: 0.228004\n",
    "    Cost after iteration 1000: 0.214820\n",
    "    Cost after iteration 1100: 0.203078\n",
    "    Cost after iteration 1200: 0.192544\n",
    "    Cost after iteration 1300: 0.183033\n",
    "    Cost after iteration 1400: 0.174399\n",
    "    Cost after iteration 1500: 0.166521\n",
    "    Cost after iteration 1600: 0.159305\n",
    "    Cost after iteration 1700: 0.152667\n",
    "    Cost after iteration 1800: 0.146542\n",
    "    Cost after iteration 1900: 0.140872\n",
    "    Cost after iteration 2000: 0.135608\n",
    "    Cost after iteration 2100: 0.130708\n",
    "    Cost after iteration 2200: 0.126137\n",
    "    Cost after iteration 2300: 0.121861\n",
    "    Cost after iteration 2400: 0.117855\n",
    "    Cost after iteration 2500: 0.114093\n",
    "    Cost after iteration 2600: 0.110554\n",
    "    Cost after iteration 2700: 0.107219\n",
    "    Cost after iteration 2800: 0.104072\n",
    "    Cost after iteration 2900: 0.101097\n",
    "    Cost after iteration 3000: 0.098280\n",
    "    Cost after iteration 3100: 0.095610\n",
    "    Cost after iteration 3200: 0.093075\n",
    "    Cost after iteration 3300: 0.090667\n",
    "    Cost after iteration 3400: 0.088374\n",
    "    Cost after iteration 3500: 0.086190\n",
    "    Cost after iteration 3600: 0.084108\n",
    "    Cost after iteration 3700: 0.082119\n",
    "    Cost after iteration 3800: 0.080219\n",
    "    Cost after iteration 3900: 0.078402\n",
    "    ```\n",
    "    \n",
    "    - Accuracy: \n",
    "    ```Python\n",
    "    train accuracy: 99.52153110047847 %\n",
    "    test accuracy: 70.0 %\n",
    "    ```\n",
    "    Definitely overfitting.  \n",
    "    \n",
    "    - Learning Rate Selection: \n",
    "    \n",
    "    <img src = 'imgs\\learning-rate-tuning.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
